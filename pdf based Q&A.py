# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11bvv7O5EAswqLlrp5thSbph1yygWotDl
"""

# ============================
# üìå INSTALL REQUIRED PACKAGES
# ============================
!pip install transformers accelerate torch pillow gradio pdfplumber sentencepiece -q

# =================================
# üìå IMPORT LIBRARIES
# =================================
import gradio as gr
from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForVision2Seq
import pdfplumber
import torch
from PIL import Image
import io

# ================================================
# üìå LOAD IBM GRANITE 3.2 2B INSTRUCT (TEXT MODEL)
# ================================================
model_name = "ibm-granite/granite-3.2-2b-instruct"

tokenizer = AutoTokenizer.from_pretrained(model_name)
text_model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    torch_dtype=torch.float16
)

# ======================================
# üìå LOAD IMAGE ANALYSIS MODEL
# (Using BLIP Base for Image Captioning)
# ======================================
vis_model_name = "Salesforce/blip-image-captioning-base"

vis_processor = AutoTokenizer.from_pretrained(vis_model_name)
vis_model = AutoModelForVision2Seq.from_pretrained(
    vis_model_name,
    device_map="auto",
    torch_dtype=torch.float16
)

# ================================
# üìå FUNCTION 1: LANGUAGE TRANSLATION
# ================================
def translate_text(input_text, target_language):
    prompt = f"Translate the following text to {target_language}:\n\n{input_text}\n\nTranslation:"
    inputs = tokenizer(prompt, return_tensors="pt").to(text_model.device)

    output = text_model.generate(
        **inputs,
        max_new_tokens=200,
        temperature=0.3
    )
    return tokenizer.decode(output[0], skip_special_tokens=True)

# ================================
# üìå FUNCTION 2: IMAGE ANALYSIS
# ================================
def analyze_image(image):
    if image is None:
        return "Please upload an image."

    image = Image.fromarray(image)
    pixel_values = vis_processor(images=image, return_tensors="pt").pixel_values.to(vis_model.device)

    output_ids = vis_model.generate(pixel_values, max_length=80)
    caption = vis_processor.batch_decode(output_ids, skip_special_tokens=True)[0]
    return caption

# ================================
# üìå FUNCTION 3: PDF READER + QA
# ================================
def extract_pdf(pdf_file, question):
    if pdf_file is None:
        return "Please upload a PDF."

    text = ""
    with pdfplumber.open(pdf_file) as pdf:
        for page in pdf.pages:
            text += page.extract_text() + "\n"

    # Ask Granite to answer based on extracted text
    prompt = f"""You are a study assistant. Here is study material from a PDF:

{text}

Now answer the following question based ONLY on the above content:

Q: {question}
A:"""

    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=4096).to(text_model.device)
    output = text_model.generate(
        **inputs,
        max_new_tokens=300,
        temperature=0.4
    )
    return tokenizer.decode(output[0], skip_special_tokens=True)

# =====================================
# üìå GRADIO USER INTERFACE
# =====================================
with gr.Blocks() as demo:
    gr.Markdown("# üìò StudyMate ‚Äì AI Study Assistant\n### Powered by IBM Granite 3.2 2B + Image & PDF Analysis")

    with gr.Tab("üåê Language Translation"):
        input_text = gr.Textbox(label="Enter text to translate")
        target_language = gr.Dropdown(["English", "Hindi", "French", "Spanish", "German", "Tamil", "Kannada"], label="Translate to")
        translate_btn = gr.Button("Translate")
        translate_output = gr.Textbox(label="Translated Text")
        translate_btn.click(translate_text, [input_text, target_language], translate_output)

    with gr.Tab("üñº Image Analysis"):
        img_in = gr.Image(type="numpy", label="Upload Image")
        img_btn = gr.Button("Analyze Image")
        img_out = gr.Textbox(label="Image Description")
        img_btn.click(analyze_image, img_in, img_out)

    with gr.Tab("üìö PDF Study Material (Q & A)"):
        pdf_in = gr.File(label="Upload PDF")
        question = gr.Textbox(label="Ask a question based on the PDF content")
        pdf_btn = gr.Button("Get Answer")
        pdf_out = gr.Textbox(label="Answer")
        pdf_btn.click(extract_pdf, [pdf_in, question], pdf_out)

demo.launch(debug=True, share=True)